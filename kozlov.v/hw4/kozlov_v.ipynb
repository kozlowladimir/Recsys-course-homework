{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrease_cardinality(\n",
    "    df: pd.DataFrame,\n",
    "    feature: str,\n",
    "    threshold: float = 0.95,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Уменьшает размерность признака по заданным параметрам\"\"\"\n",
    "    x = df[feature].value_counts(1).cumsum()\n",
    "    values = x[x >= threshold].index\n",
    "    df.loc[df[feature].isin(values), feature] = values.min()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # на мобильных устройствах и ПК удобство просмотра одних и тех же зон может быть разным\n",
    "    df['zone_id_os_id'] = df['zone_id'].astype('str') + '_' + df['os_id'].astype('str')\n",
    "    \n",
    "    # возможно, что некоторые баннеры показываются только \n",
    "    # в определнных местах и из-за этого плохие клики\n",
    "    df['banner_id_zone_id'] = df['banner_id'].astype('str') + '_' + df['zone_id'].astype('str')\n",
    "\n",
    "    # в разных странах может быть разная реакция на один и тот же баннер\n",
    "    df['banner_id_country_id'] = df['banner_id'].astype('str') + '_' + df['country_id'].astype('str')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_and_fit_model(x_train: sparse, y_train: pd.Series, C=1):\n",
    "    \"\"\"Инитит обучает логрег модель.\"\"\"\n",
    "    lr = LogisticRegression(solver='liblinear', C=C)\n",
    "    return lr.fit(x_train, y_train.values)\n",
    "\n",
    "def cv(\n",
    "    x_train: sparse,\n",
    "    y_train: pd.Series,\n",
    "    indexes: List[Tuple[int]],\n",
    "    C=1,\n",
    "    is_sliding=True\n",
    "): \n",
    "    \"\"\"\n",
    "    Производит кроссвалидацию по времени. Возможны два режима работы: скользящим окном\n",
    "    или расширающимся окном. В скользящем окне обучение происходит за промежуток времени,\n",
    "    который каждый раз смещается вперед во времени. В расширяющемся окне данные для обучения\n",
    "    все время увеличиваются вперед во времени.\n",
    "    \n",
    "    @param: x_train Спарс матрица с тренировочными данными\n",
    "    @param: y_train pd.Series с таргетами\n",
    "    @param: indexes Индексы для создания трейна и валидации\n",
    "    @param: C обратный коэффициент регуляриации \n",
    "    @param: is_sliding использовать сколзящее окно или нет.\n",
    "    \n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    models = []\n",
    "    \n",
    "    # Стартовый индекс для расширяющегося окна\n",
    "    train_start_index = indexes[0][0]\n",
    "    \n",
    "    for train_ind_start, train_ind_end, val_ind_end in indexes:\n",
    "        if is_sliding:\n",
    "            x_train_inner = x_train[train_ind_start: train_ind_end]\n",
    "            y_train_inner = y_train[train_ind_start: train_ind_end]\n",
    "\n",
    "            x_val_inner = x_train[train_ind_end: val_ind_end]\n",
    "            y_val_inner = y_train[train_ind_end: val_ind_end]\n",
    "        else:\n",
    "            x_train_inner = x_train[train_start_index: train_ind_end]\n",
    "            y_train_inner = y_train[train_start_index: train_ind_end]\n",
    "\n",
    "            x_val_inner = x_train[train_ind_end: val_ind_end]\n",
    "            y_val_inner = y_train[train_ind_end: val_ind_end]\n",
    "        \n",
    "        print(f'Train size: {x_train_inner.shape[0]}')\n",
    "        print(f'Valid size: {x_val_inner.shape[0]}')\n",
    "        \n",
    "        model = create_and_fit_model(x_train_inner, y_train_inner, C=C)\n",
    "        predict = model.predict_proba(x_val_inner)[:, 1]\n",
    "        \n",
    "        loss = log_loss(y_val_inner, predict)\n",
    "        print(f'Logloss: {round(loss, 4)}')\n",
    "        \n",
    "        losses.append(loss)\n",
    "        models.append(model)\n",
    "         \n",
    "    return losses, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '../hw3/data/data.csv',\n",
    "    usecols=[     \n",
    "        'date_time',\n",
    "        'zone_id',\n",
    "        'banner_id',\n",
    "        'os_id',\n",
    "        'country_id',\n",
    "        'clicks',\n",
    "        'banner_id0',\n",
    "        'coeff_sum0',\n",
    "        'g0',\n",
    "        'banner_id1',\n",
    "        'coeff_sum1',\n",
    "        'g1',\n",
    "    ],\n",
    "    dtype={\n",
    "        'zone_id': np.uint16, \n",
    "        'banner_id': np.uint16,\n",
    "        'campaign_clicks': np.uint16,\n",
    "        'os_id': np.uint8,\n",
    "        'country_id': np.uint8,\n",
    "        'clicks': np.uint8,\n",
    "    }\n",
    ")\n",
    "\n",
    "df = df.sort_values('date_time')\n",
    "df = df[1:].reset_index(drop=True)\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "\n",
    "df = decrease_cardinality(df, 'zone_id')\n",
    "df = decrease_cardinality(df, 'banner_id')\n",
    "\n",
    "train_index_max = df[df['date_time'] < '2021-10-02'].index.max()\n",
    "test_index_max = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[train_index_max:].copy()\n",
    "temp_df['banner_id'] = temp_df['banner_id1']\n",
    "\n",
    "df = pd.concat([df, temp_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = feature_engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_encoder = OneHotEncoder()\n",
    "scaller = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('2021-09-26', '2021-10-02', freq='1d')\n",
    "indexes = [df[df['date_time'] >= date].index.min() for date in dates]\n",
    "indexes = tuple(zip(indexes[:-2], indexes[1:-1], indexes[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sparse.hstack([\n",
    "    one_encoder.fit_transform(df[['banner_id_country_id']]),\n",
    "    one_encoder.fit_transform(df[['banner_id_zone_id']]),\n",
    "    one_encoder.fit_transform(df[['banner_id']]),\n",
    "    one_encoder.fit_transform(df[['zone_id_os_id']]),\n",
    "    one_encoder.fit_transform(df[['zone_id']]),\n",
    "    one_encoder.fit_transform(df[['os_id']]),\n",
    "    one_encoder.fit_transform(df[['country_id']]),\n",
    "])\n",
    "\n",
    "data = data.tocsr()\n",
    "\n",
    "x_train, x_test = data[:train_index_max], data[train_index_max:]\n",
    "y_train, y_test = df.iloc[:train_index_max]['clicks'], df.iloc[train_index_max:]['clicks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3102610\n",
      "Valid size: 2367303\n",
      "Logloss: 0.0812\n",
      "Train size: 2367303\n",
      "Valid size: 2307355\n",
      "Logloss: 0.088\n",
      "Train size: 2307355\n",
      "Valid size: 2420588\n",
      "Logloss: 0.1143\n",
      "Train size: 2420588\n",
      "Valid size: 1851189\n",
      "Logloss: 0.1357\n",
      "Train size: 1851189\n",
      "Valid size: 1643447\n",
      "Logloss: 0.1491\n"
     ]
    }
   ],
   "source": [
    "losses, models = cv(x_train, y_train, indexes, C=0.16681)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = [model.predict_proba(x_test)[:, 1] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07803494335292893"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_day_df = df.iloc[train_index_max:test_index_max][[\n",
    "    'banner_id', 'banner_id0', 'g0', 'coeff_sum0', 'banner_id1', 'g1', 'coeff_sum1', 'clicks',\n",
    "]]\n",
    "last_day_df['banner_id0_proba'] = predict[-1][:test_index_max-train_index_max]\n",
    "last_day_df['banner_id1_proba'] = predict[-1][test_index_max-train_index_max:]\n",
    "\n",
    "# почему-то есть несколько строк с g1 < 0\n",
    "last_day_df = last_day_df[last_day_df['g1'] >= 0].reset_index(drop=True)\n",
    "\n",
    "last_day_df['coeff_sum0_new'] = np.log(last_day_df['banner_id0_proba']/(1-last_day_df['banner_id0_proba']))\n",
    "last_day_df['coeff_sum1_new'] = np.log(last_day_df['banner_id1_proba']/(1-last_day_df['banner_id1_proba']))\n",
    "\n",
    "last_day_df['N0'] = np.random.normal(last_day_df['coeff_sum0'], last_day_df['g0']**2)\n",
    "last_day_df['N1'] = np.random.normal(last_day_df['coeff_sum1'], last_day_df['g1']**2)\n",
    "last_day_df['p0'] = 1 - norm.cdf(\n",
    "    (- last_day_df['coeff_sum0'] + last_day_df['coeff_sum1'])/(np.abs(last_day_df['g0']**2 + last_day_df['g1']**2)**0.5)  \n",
    ")\n",
    "\n",
    "last_day_df['N0_new'] = np.random.normal(last_day_df['coeff_sum0_new'], last_day_df['g0']**2)\n",
    "last_day_df['N1_new'] = np.random.normal(last_day_df['coeff_sum1_new'], last_day_df['g1']**2)\n",
    "last_day_df['p0_new'] = 1 - norm.cdf(\n",
    "    (- last_day_df['coeff_sum0_new'] + last_day_df['coeff_sum1_new'])/(np.abs(last_day_df['g0']**2 + last_day_df['g1']**2)**0.5)\n",
    ")\n",
    "\n",
    "last_day_df['ratio'] = last_day_df['p0_new']/last_day_df['p0']\n",
    "\n",
    "last_day_df['lambda'] = 10\n",
    "\n",
    "# рассматриваем только те случаи в которых был показан banner_id0\n",
    "cond = (last_day_df['banner_id'] == last_day_df['banner_id0'])\n",
    "\n",
    "(last_day_df[cond]['clicks']*last_day_df[cond][['ratio', 'lambda']].min(axis=1)).sum()/last_day_df[cond].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035221482500836836"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_day_df['clicks'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задавал вопрос в чате на тему интерпретируемости cips и получил ответ, что стоит относится к нему к ctr, который бы у нас получился если бы мы действовали новым полиси в тот момент когда показывали баннеры, на которых был посчитан cips.\n",
    "\n",
    "По результатам работы получил cips 0.78, что меня насторожило. В реальной жизни ctr 7.8% на общей выборке показов баннеров кажется чем-то высоким. Согласен, что отдельные баннеры в особенных кампаниях возможно и могут его достичь, но для среднего по больнице это много. Все дело в лямбде и в формуле. Мы считаем отношение вероятностей (вероятность того, что баннер 0 будет кликнут при показе баннера 0 и 1) новой и старой полиси вот только тут опять возникают вопросы:\n",
    "<li>Два ли баннера соревнуются в показе между собой или на самом деле их намного больше?</li>\n",
    "<li>Почему в новой полиси мы по прежднему сравниваем баннер 0 и баннер 1? Ведь в новой полиси возможно имеет смысл сравнивать баннер 0 с баннером 100 или с банннером 200 т.к. у них будет выше вероятность показа чем у баннера 1.</li>\n",
    "<li>Каким образом происходят показы если вероятность показать баннер 0 чуть больше чем вероятность показать баннер 1? Если мы всегда показываем тот баннер чья вероятность выше, то совершенно неправильно оценивать ctr по cips. Во сколько бы раз вероятность новой полиси не была больше вероятности старой бОльшую награду мы с этого не получим</li>\n",
    "<li>Параметр лямбда вообще может и не быть равен 10</li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
